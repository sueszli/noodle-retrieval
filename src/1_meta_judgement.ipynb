{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- query id: trip_1337, doc id: trip_4728579\n",
      "- expert votes: [2 2 2] (mean: 2.00, median: 2, mode: 2)\n",
      "- similarity vote: 2\n",
      "- aggregated vote: 2\n",
      "\n",
      "\n",
      "- query id: trip_443528, doc id: trip_9943688\n",
      "- expert votes: [0 0 0] (mean: 0.00, median: 0, mode: 0)\n",
      "- similarity vote: 2\n",
      "- aggregated vote: 0\n",
      "\n",
      "\n",
      "- query id: rob_q_FT933-11533, doc id: rob_FT924-4715\n",
      "- expert votes: [0 2 1] (mean: 1.00, median: 1, mode: 0)\n",
      "- similarity vote: 1\n",
      "- aggregated vote: 1\n",
      "\n",
      "\n",
      "- query id: trip_57861, doc id: trip_5571694\n",
      "- expert votes: [3 1 2] (mean: 2.00, median: 2, mode: 3)\n",
      "- similarity vote: 2\n",
      "- aggregated vote: 2\n",
      "\n",
      "\n",
      "- query id: rob_qq_FR940811-1-00004, doc id: rob_FR940811-1-00004\n",
      "- expert votes: [0 0 0] (mean: 0.00, median: 0, mode: 0)\n",
      "- similarity vote: 2\n",
      "- aggregated vote: 0\n",
      "\n",
      "\n",
      "- query id: rob_qq_FR940318-0-00056, doc id: rob_FR940106-0-00031\n",
      "- expert votes: [1 0 0] (mean: 0.33, median: 0, mode: 0)\n",
      "- similarity vote: 3\n",
      "- aggregated vote: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sueszli/.asdf/installs/python/3.11.9/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "\n",
    "base_in = Path.cwd().parent / \"data-merged\" / \"data-merged\" / \"air-exercise-2\" / \"Part-1\"\n",
    "base_in_prev = Path.cwd().parent / \"data-merged\" / \"data-merged\"  # output of previous script\n",
    "base_out = Path.cwd().parent / \"output\"\n",
    "\n",
    "docs = pd.read_csv(base_in_prev / \"fira-22.documents.embeddings.tsv\", sep=\"\\t\")\n",
    "queries = pd.read_csv(base_in_prev / \"fira-22.queries.embeddings.tsv\", sep=\"\\t\")\n",
    "judgements: pd.DataFrame = pd.read_csv(base_in / \"fira-22.judgements-anonymized.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "def preprocess_docs(docs: pd.DataFrame) -> pd.DataFrame:\n",
    "    docs = docs[docs[\"doc_id\"].isin(judgements[\"documentId\"].unique())]\n",
    "    len_j = len(judgements[\"documentId\"].unique())\n",
    "    len_d = len(docs[\"doc_id\"].unique())\n",
    "    assert len_j == len_d\n",
    "    return docs\n",
    "\n",
    "\n",
    "def preprocess_queries(queries: pd.DataFrame) -> pd.DataFrame:\n",
    "    queries = queries[queries[\"query_id\"].isin(judgements[\"queryId\"].unique())]\n",
    "    len_j = len(judgements[\"queryId\"].unique())\n",
    "    len_q = len(queries[\"query_id\"].unique())\n",
    "    assert len_j == len_q\n",
    "    return queries\n",
    "\n",
    "\n",
    "def preprocess_judgements(judgements: pd.DataFrame) -> pd.DataFrame:\n",
    "    prev_len = len(judgements)\n",
    "    judgements = judgements.dropna().drop_duplicates()\n",
    "    assert len(judgements) == prev_len\n",
    "    judgements = judgements[[\"relevanceLevel\", \"queryId\", \"documentId\"]]\n",
    "    judgements[\"relevanceLevel\"] = judgements[\"relevanceLevel\"].map({\"0_NOT_RELEVANT\": 0, \"1_TOPIC_RELEVANT_DOES_NOT_ANSWER\": 1, \"2_GOOD_ANSWER\": 2, \"3_PERFECT_ANSWER\": 3})\n",
    "    return judgements\n",
    "\n",
    "\n",
    "def get_cos_similarity(q_id: str, d_id: str) -> float:\n",
    "    q_embedding: torch.tensor = torch.tensor([float(i) for i in queries[queries[\"query_id\"] == q_id][\"query_embedding\"].values[0].strip(\"[]\").split(\", \")]).unsqueeze(0)  # type: ignore\n",
    "    d_embedding: torch.tensor = torch.tensor([float(i) for i in docs[docs[\"doc_id\"] == d_id][\"doc_embedding\"].values[0].strip(\"[]\").split(\", \")]).unsqueeze(0)  # type: ignore\n",
    "    sim: float = cosine_similarity(q_embedding, d_embedding).item()\n",
    "    assert 0 <= sim <= 1\n",
    "    return sim\n",
    "\n",
    "\n",
    "docs = preprocess_docs(docs)  # \"doc_id\", \"doc_embedding\"\n",
    "queries = preprocess_queries(queries)  # \"query_id\", \"query_embedding\"\n",
    "judgements = preprocess_judgements(judgements)  # \"relevanceLevel\", \"queryId\", \"documentId\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SAMPLE_SIZE = 5\n",
    "    \n",
    "    # randomize query order\n",
    "    queries = queries.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    for _, q in queries.iterrows():\n",
    "        q_id = q[\"query_id\"]\n",
    "        d_ids = judgements[judgements[\"queryId\"] == q_id][\"documentId\"].unique()\n",
    "\n",
    "        # randomize doc order\n",
    "        d_ids = np.random.permutation(d_ids)\n",
    "\n",
    "        for doc_id in d_ids:\n",
    "            votes = judgements[judgements[\"documentId\"] == doc_id][\"relevanceLevel\"].values\n",
    "            sim = get_cos_similarity(q_id, doc_id)\n",
    "\n",
    "            doc_content = docs[docs[\"doc_id\"] == doc_id][\"doc_text\"].values[0]\n",
    "            query_content = queries[queries[\"query_id\"] == q_id][\"query_text\"].values[0]\n",
    "            print(f\"- query id: {q_id}, doc id: {doc_id}\")\n",
    "\n",
    "            sim_vote = 3 if sim >= 0.75 else 2 if sim >= 0.5 else 1 if sim >= 0.25 else 0\n",
    "            print(f\"- expert votes: {votes} (mean: {np.mean(votes):.2f}, median: {int(np.median(votes))}, mode: {Counter(votes).most_common(1)[0][0]})\")\n",
    "            print(\"- similarity vote:\", sim_vote)\n",
    "            votes = np.append(votes, sim_vote)\n",
    "\n",
    "            agg_vote = np.round(np.mean(votes)).astype(int)\n",
    "            assert agg_vote in [0, 1, 2, 3]\n",
    "\n",
    "            print(f\"- aggregated vote: {agg_vote}\\n\\n\")\n",
    "\n",
    "            # go to next query\n",
    "            break\n",
    "\n",
    "        # limit to sample size\n",
    "        if SAMPLE_SIZE == 0:\n",
    "            sys.exit(0)\n",
    "        SAMPLE_SIZE -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
